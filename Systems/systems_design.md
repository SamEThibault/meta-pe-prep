# Systems Design Basics
## Web Servers and Load Balancing
NGINX: open-source web server software used for reversee proxy, load balancing, and caching. It's event-driven, asynchronous, and uses master-slave architecture.

NGINX as a web server:
- serves static content

NGINX as a reverse proxy:
- forwards client requests to the appropriate backend server (or local application)

Most of the time, NGINX is used as a layer 7 (Application layer) load balancer:
- Receives requests directly from clients, and forwards them to the appropriate backend server
- It can also cache resources, and serve them directly to clients
- It can also terminate SSL/TLS connections, and forward unencrypted requests to the backend server (allowing for faster interal communication and processing times). Sometimes it's worth it and practical (in very secure environments), but usually you'd want to have SSL/TLS end-to-end.

Let's not forget there's also Apache, which came first. It's a bit more feature-rich, but it's not as fast as NGINX. It's also more resource-intensive.

BTW, you can also use layer 4 load balancers, which direct traffic based on IP address and port number and don't need to consider the actual content of the request.

#### Static vs Dynamic Content Delivery
Static Content: content that doesn't change often, like images, CSS, and JavaScript files. It's served directly to the client by the web server (or in most cases, cached and sent by the CDN).

Dynamic Content: content that changes often, like user-generated content, or content that needs to be generated on-the-fly. It's generated by the application server, and then served to the client.

## CDNs
Content Delivery Network: Service that accelerates internet content delivery.

Scenario: we have users all over the world, but our servers are not as distributed. 

We want to physically reduce the distance between the user and server delivering the content. So we place content delivery endpoints in as many locations as possible, these cache whatever content we would originally serve from the server. And the users can query the CDNs directly, drastically reducing round trip delays, and reducing the load on the main server.

These are used for data-heavy aplication. A CDN can delivers both static and dynamic content. Static content is cached, while dynamic content requires CDNs to reconnect with the origin server for each request. But they accelerate the delivery process by optimizing the connection between themselves and the origin servers, as oppposed to the user connecting directly to the origin server. When going through CDNs, you don't need to establish a new connection for each request, that's already assumed to be completed and ready for transmissions. You can also take advantage of your Edge CDN servers to validate user requests.

## In-memory Caches
Redis: in-memory data store (key-val). Traditionally used as a caching layer serverside, data stored in RAM (fast). Stores frequently sent requests to reduce DB loads. 

## Browser Caches
On-device storing of static web content. Browsers store these files until their time to live (TTL) expires or until the hard drive cache is full. 

## Distributed Systems
A collection of computer programs that utilize computational resources across multiple separate nodes to achieve a common, shared goal.

They aim to achieve:
- Scalability (ability to handle increased load)
- Fault Tolerance (ability to handle failures)
- Concurrency (Components operate simultaneously and independently)
- No Single Point of Failure (if one component fails, the system can still operate)

CAP Theorem:
- Consistency: all nodes see the same data simultaneously
- Availability: Every request receives a response, even if some nodes are down
- Partition Tolerance: The system continues to operate despite network partitions

Data Replication:
- Data is copied across multiple nodes to improve reliability and performance
- There's multiple replication techniques:
    - Leader-Follower replication: One node handles writes, other nodes replicate data
    - Multi-Leader replication: Multiple leaders handle writes: conflict resolution is needed
    - Eventual Consistency: Data becomes consistent over time

Sharding:
- We divide data across multiple nodes based on a shard key (user ID, for ex)
- Horizontal Scaling: each node stores a subset of data

There's both local and global caching with distributed systems:
- Local: Redis, on a single node
- Global: CDNs like Cloudflare that service multiple nodes

Distributed System Architectures:
- Client-Server: Clients request resources from a central server
- Peer-to-Peer: Nodes are both clients and servers, sharing resources directly
- Master-Slave: A master node manages one or more slave nodes
- Microservices: Application is dividedd into small, independently deployable services
- Even-Driven: Components communicate by emitting and consuming events

Best Practices:
- Assume nodes will fail, use retries, replication, and fallbacks
- Ensure repeated operations don't cause unintended side effects
- Use tools like Promehteus and Grafana for observability
- Simulate failures to ensure resilience in production

# Building Scalable Systems
Here is a list of technologies and methodologies that major companies use to build scalable systems:
- When there might be complex relationships between data, use a graph database. It closely mimics the organic relationships that form in common social media platforms.
- Automate as much as possible. 
- Application nodes should be stateless to simplify consistency and load balancing.
- Object storage (S3) should be used for images and other static files.
- Large tasks should be queued, with workers processing them asynchronously to avoid app response bottlenecks.
- For notification purposes, web sockets should be used. They allow for bi-directional communication between the server and client. However, web sockets tend to be stateful, so they should be used sparingly.
- Sharding: Splitting data across multiple databases to improve performance and scalability. For example, a user database can be split into 2, where one database stores users with even IDs and the other stores users with odd IDs.
- The publish-subscribe communication model is often used because of its scalability. If a company wants to develop a new feature that depends on the existing data stream, they can just subscribe to the data stream and process the data as needed. The data stream is not affected/unaware of the new feature.

# How would I design Spotify?
1. Identify key features: Songs, playlists, users, artists, podcasts
2. Define problem scope: Ask what should be the focus? For this example: Finding and playing music
3. Define use cases: browse music, search for song, play song
4. Think about metrics: How many users? A billion. How many songs? 100 million. File size: assume about 5 MB per song. So around 500TB of total song data. With 3x replication, Around 1.5PB. Metadata: 100B per song ish, so 10GB total, not a factor.
5. High level overview: Client application, Load balancer, replicated web servers, Database
6. Outline the DB schemas: How many DBs? One for metadata (users, songs, artists...), One for song audio. Why split this into 2? We have static content: the song files. So use S3 for that. For metadata, use a relational DB. Schema for RDS: song_id, song_url, artist, genre, link to album cover, audio_link
7. Drill down on use cases: 
    - User searches for a song: goes through LB, to web server, to metadata DB, which returns a list of songs that match the query. That's pretty efficient. 
    - User playes a song: goes through LB, to web server, to metadata DB, which returns song URL. Then web server has to fetch the song from S3 and stream it to the user. To stream, you need a web socket connection which allows constant communication between server and client. That might not be necessary: Just wait for the client to have entire song in memory before starting to play it. That eliminates possible lags.
8. Think about bottlenecks:
    - Inefficient streaming for songs with high volume of requests: can easily overload song bucket. Takes alot of bandwidth for the web servers as well. Solution: CDNs as song audio caches. Relieves load on S3 and web servers.
    - Caching metadata: Use Redis to cache metadata. Relieves load on the RDS DB and ensures that popular requests are efficiently served.
    - Think about cache on the server level: Maybe a distributed cache, like Memcached, to cache song URLs and relieve load on the DBs. Maybe load entire songs on the web servers to avoid streaming from S3. (Multi-layer caching)

# Design a botnet that can exploit 10000 low-end machines to run code. All machines need to crawl web pages and return results. No machine should crawl a page twice.

# Design a system that stores and retrieves images for Facebook

# How would you design a cache API?

# How would you design a system that manipulates content sent from a client? (clean offensive words for ex)